ğŸ¼ Maternal Health Risk Prediction
ğŸ“Œ Introduction

ğŸ“ Problem statement: Predict the maternal health risk category (low, mid, high) for pregnant women using clinical features (age, blood pressure, blood sugar, body temperature, heart rate, etc.).

ğŸ¯ Objective: Build and compare classification models to predict maternal health risk and identify important predictors for early intervention.

ğŸ“Š Dataset: Tabular dataset with features:

Age ğŸ‘©â€ğŸ¦³

SystolicBP & DiastolicBP ğŸ«€

Blood Sugar (BS) ğŸ¬

Body Temperature ğŸŒ¡ï¸

Heart Rate â¤ï¸â€ğŸ”¥

Target â†’ RiskLevel (Low, Mid, High)

ğŸ” Steps of Analysis
1ï¸âƒ£ Data Loading & Inspection

ğŸ“¥ Read dataset into DataFrame & view first rows

ğŸ” Check data types, missing values, basic stats

2ï¸âƒ£ Data Cleaning & Preprocessing

ğŸ§¹ Handle missing values

ğŸ” Encode categorical target (RiskLevel)

âš–ï¸ Scale features (if needed)

âœ‚ï¸ Train/test split

3ï¸âƒ£ Exploratory Data Analysis (EDA)

ğŸ“¦ Class distribution for RiskLevel

ğŸ“ˆ Histograms & Boxplots â†’ feature distributions & outliers

ğŸ”¥ Correlation Heatmap â†’ check multicollinearity

ğŸ¨ Pairplots/Scatter plots â†’ class separation

4ï¸âƒ£ Model Building

Models trained:

ğŸ“‰ Logistic Regression

ğŸŒ³ Decision Tree Classifier

ğŸŒ² Random Forest Classifier

ğŸ’¡ Support Vector Classifier (SVC)
â¡ï¸ Multiple hyperparameter runs for Random Forest & Decision Tree

5ï¸âƒ£ Evaluation

ğŸ“‘ Metrics: Accuracy, Precision, Recall, F1-score

ğŸŸ¦ Confusion Matrices with plots

ğŸ“Š Feature Importance (Random Forest)

ğŸ“ˆ Results

Logistic Regression: 61% âœ…

Decision Tree: 86% ğŸŒ³

Random Forest: 87â€“88% ğŸŒ²ğŸ”¥ (Best performer)

SVC: 67% ğŸ’¡

ğŸ” Key Takeaways:

Random Forest gave the best accuracy (~88%) ğŸ†

Logistic Regression performed worst (61%), showing non-linear patterns dominate

Mid-risk class harder to identify â†’ lower recall/F1 in some models

Low & High risk performed better overall

ğŸ“Š Explanation of Key Graphs

ğŸ“¦ Class Distribution Bar Chart â†’ shows balance/imbalance

ğŸ“ˆ Histograms & Boxplots â†’ reveal skewness/outliers (e.g., BP extremes)

ğŸ”¥ Correlation Heatmap â†’ detect multicollinearity

ğŸ¨ Pairplots â†’ check feature separability by RiskLevel

ğŸŒ² Feature Importance (RF) â†’ SystolicBP, Age, etc. most predictive

ğŸŸ¦ Confusion Matrix â†’ shows which classes are confused (e.g., mid risk â†’ low risk)

ğŸ“ Model Performance Metrics

Accuracy: 0.61, 0.86, 0.87, 0.88, 0.67

Precision: Correctness of positive predictions

Recall: Coverage of actual positives

F1-Score: Balance of precision & recall

ğŸ’¡ Insight: A high precision but low recall on high risk â†’ model misses cases but avoids false alarms

ğŸ› ï¸ Technologies Used

 Python 3

ğŸ“¦ Libraries:

pandas, numpy â†’ data handling

matplotlib, seaborn â†’ visualization

scikit-learn â†’ models & evaluation
